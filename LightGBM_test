# -*- coding = utf-8 -*-
# @Time : 2023/10/12 13:07
# @Author : gao
# @File : LightGBM_test.py

import os
import time
import pandas as pd
import numpy as np
import pydotplus
from pydotplus import graph_from_dot_data
from sklearn.tree import export_graphviz
from sklearn.preprocessing import MinMaxScaler
from scipy.stats import pearsonr
from sklearn.model_selection import cross_val_score, KFold, train_test_split
from lightgbm import LGBMRegressor
from sklearn import datasets
import lightgbm as lgb

train_dir = r"G:\Desktop\data processing\research data\input data\train_nona"
output_dir = r"G:\Desktop\data processing\research data\input data\results\LightGBM"

# 创建一个空的DataFrame用于保存结果
result_df = pd.DataFrame(columns=["LightGBM", "r_scores", "nse_scores", "kge_scores"])

# 遍历训练数据集的CSV文件
for file_name in os.listdir(train_dir):
    if file_name.endswith(".csv"):
        start_time = time.time()  # 程序开始时间

        # 读入训练数据集
        train_data = pd.read_csv(os.path.join(train_dir, file_name))

        # 删除含有nan的行
        train_data_nona = train_data.dropna(axis=0, how='any')

        # 分离特征和目标变量
        X = train_data_nona[['pre', 'temp', 'wind', 'pet', 'SMsurf', 'SMroot']]
        y = train_data_nona['runoff']

        # 定义性能评估指标的列表
        r_scores = []
        nse_scores = []
        kge_scores = []

        # 定义K折交叉验证的参数
        k = 5  # K的值
        kf = KFold(n_splits=k, shuffle=True, random_state=42)

        # 进行交叉验证
        for train_index, test_index in kf.split(X):
            X_train, X_test = X.iloc[train_index], X.iloc[test_index]
            y_train, y_test = y.iloc[train_index], y.iloc[test_index]

            # 数据归一化
            scaler = MinMaxScaler()
            X_train_norm = scaler.fit_transform(X_train)
            X_test_norm = scaler.transform(X_test)

            # 初始化LightGBM模型
            # boosting_type = 'gbdt', learning_rate = 0.01, n_estimators = 1000, max_depth = 5, num_leaves = 124
            LightGBM = LGBMRegressor(boosting_type='gbdt', learning_rate=0.01, n_estimators=1000, max_depth=10, num_leaves=50)

            # 训练梯度提升树回归模型
            LightGBM.fit(X_train_norm, y_train)

            # 在测试集上进行预测
            y_pred = LightGBM.predict(X_test_norm)

            # 计算皮尔逊相关系数
            r = pearsonr(y_test, y_pred)
            print("r:", r)
            r_scores.append(r[0])

            # 计算NSE
            def nse(y_test, y_pred):
                mean_y_test = np.mean(y_test)
                numerator = np.sum((y_test - y_pred) ** 2)
                denominator = np.sum((y_test - mean_y_test) ** 2)
                nse_value = 1 - numerator / denominator
                return nse_value
            nse_value = nse(y_test, y_pred)
            print('NSE:', nse_value)
            nse_scores.append(nse_value)

            # 计算KGE
            def calculate_kge(y_test, y_pred):
                r = np.corrcoef(y_test, y_pred)[0, 1]  # 计算相关系数
                alpha = np.std(y_pred) / np.std(y_test)  # 计算标准差比例
                beta = np.mean(y_pred) / np.mean(y_test)  # 计算均值比例
                kge = 1 - np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)  # 计算KGE
                return kge
            kge_value = calculate_kge(y_test, y_pred)
            print("KGE:", kge_value)
            kge_scores.append(kge_value)

        # 将交叉验证结果添加到result_df中
        result_df = pd.concat([result_df, pd.DataFrame({"LightGBM": [file_name],
                                                        "r_scores": np.mean(r_scores),
                                                        "nse_scores": np.mean(nse_scores),
                                                        "kge_scores": np.mean(kge_scores)})],
                              ignore_index=True)

# 将结果保存到文件中
result_file_path = os.path.join(output_dir, "result_LightGBM_交叉验证_训练集1.csv")
result_df.to_csv(result_file_path, index=False)

print("所有结果已保存到文件中：", result_file_path)
